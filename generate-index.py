#!/usr/bin/env python3
"""
vFlowä»“åº“ç´¢å¼•ç”Ÿæˆå™¨
è‡ªåŠ¨æ‰«æworkflowså’Œmodulesç›®å½•å¹¶ç”Ÿæˆindex.json
"""

import json
import os
import sys
import zipfile
from datetime import datetime
from pathlib import Path


def normalize_workflow_id(filename):
    """ä»æ–‡ä»¶åè·å–å·¥ä½œæµIDï¼ˆå»é™¤.jsonæ‰©å±•åï¼‰"""
    return filename.replace('.json', '') if filename.endswith('.json') else filename


def normalize_module_id(filename):
    """ä»æ–‡ä»¶åè·å–æ¨¡å—IDï¼ˆå»é™¤.zipæ‰©å±•åï¼‰"""
    return filename.replace('.zip', '') if filename.endswith('.zip') else filename


# ==================== å·¥ä½œæµç›¸å…³å‡½æ•° ====================

def validate_workflow(data, filename):
    """
    éªŒè¯å·¥ä½œæµæ•°æ®
    è¿”å›: (is_valid, error_message, cleaned_data)
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰_meta
    if '_meta' not in data:
        return False, f"ç¼ºå°‘ '_meta' å­—æ®µ", None

    meta = data['_meta']

    # éªŒè¯_metaå¿…éœ€å­—æ®µ
    required_meta_fields = ['id', 'name', 'description', 'author', 'version', 'vFlowLevel']
    missing_fields = [field for field in required_meta_fields if field not in meta]

    if missing_fields:
        return False, f"_metaç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}", None

    # éªŒè¯_metaä¸­çš„IDä¸æ–‡ä»¶åä¸€è‡´
    expected_id = normalize_workflow_id(filename)
    meta_id = meta['id']

    if meta_id != expected_id:
        return False, f"_meta.id ä¸åŒ¹é…: æ–‡ä»¶å='{expected_id}', _meta.id='{meta_id}'", None

    return True, None, data


def clean_workflow_for_repo(data):
    """
    æ¸…ç†å·¥ä½œæµæ•°æ®ï¼Œå‡†å¤‡å‘å¸ƒåˆ°ä»“åº“
    - å°†isEnabledã€isFavoriteã€wasEnabledBeforePermissionsLostè®¾ç½®ä¸ºfalse
    - ä¿ç•™_metaä¿¡æ¯
    """
    cleaned = data.copy()

    # å¼ºåˆ¶è®¾ç½®ä¸ºfalseçš„å­—æ®µ
    cleaned['isEnabled'] = False
    cleaned['isFavorite'] = False
    cleaned['wasEnabledBeforePermissionsLost'] = False

    return cleaned


def scan_workflows_directory(directory_path):
    """
    æ‰«æç›®å½•ä¸­çš„æ‰€æœ‰å·¥ä½œæµJSONæ–‡ä»¶
    è¿”å›: (valid_items, errors, skipped_files)
    """
    items = []
    errors = []
    skipped_files = []

    dir_path = Path(directory_path)

    if not dir_path.exists():
        print(f"âš ï¸  å·¥ä½œæµç›®å½•ä¸å­˜åœ¨: {directory_path}")
        return items, errors, skipped_files

    # éå†ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶
    for filepath in dir_path.glob('*.json'):
        # è·³è¿‡index.json
        if filepath.name == 'index.json':
            continue

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # éªŒè¯å·¥ä½œæµ
            is_valid, error_msg, _ = validate_workflow(data, filepath.name)

            if not is_valid:
                errors.append(f"âŒ {filepath.name}: {error_msg}")
                skipped_files.append(filepath.name)
                continue

            # æå–å…ƒæ•°æ®
            meta = data.get('_meta', {})

            # æ¸…ç†å·¥ä½œæµæ•°æ®ï¼ˆä¿å­˜åˆ°ä»“åº“çš„ç‰ˆæœ¬ï¼‰
            cleaned_workflow = clean_workflow_for_repo(data)

            # æ„å»ºç´¢å¼•æ¡ç›®
            item = {
                'id': meta.get('id', normalize_workflow_id(filepath.name)),
                'name': meta.get('name', 'æœªå‘½å'),
                'description': meta.get('description', ''),
                'author': meta.get('author', 'æœªçŸ¥'),
                'version': meta.get('version', '1.0.0'),
                'vFlowLevel': meta.get('vFlowLevel', 1),
                'homepage': meta.get('homepage', ''),
                'tags': meta.get('tags', []),
                'updated_at': meta.get('updated_at', ''),
                'filename': filepath.name,
                # æ„å»ºä¸‹è½½URL
                'download_url': f"https://raw.githubusercontent.com/ChaoMixian/vFlow-Repos/main/workflows/{filepath.name}",
                # æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè„šæœ¬æ›´æ–°æ–‡ä»¶ï¼‰
                'local_path': str(filepath)
            }

            items.append(item)

            # è‡ªåŠ¨æ›´æ–°æ¸…ç†åçš„å·¥ä½œæµæ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(cleaned_workflow, f, ensure_ascii=False, indent=2)

            print(f"âœ… {filepath.name}: {item['name']} (v{item['version']}, Level {item['vFlowLevel']})")

        except json.JSONDecodeError as e:
            errors.append(f"âŒ {filepath.name}: JSONè§£æé”™è¯¯ - {str(e)}")
            skipped_files.append(filepath.name)
        except Exception as e:
            errors.append(f"âŒ {filepath.name}: {str(e)}")
            skipped_files.append(filepath.name)

    return items, errors, skipped_files


# ==================== æ¨¡å—ç›¸å…³å‡½æ•° ====================

def validate_module(manifest, filename):
    """
    éªŒè¯æ¨¡å—manifestæ•°æ®
    è¿”å›: (is_valid, error_message)
    """
    # éªŒè¯å¿…éœ€å­—æ®µ
    required_fields = ['id', 'name', 'description', 'author', 'version', 'category']
    missing_fields = [field for field in required_fields if field not in manifest]

    if missing_fields:
        return False, f"manifestç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}"

    # éªŒè¯IDä¸æ–‡ä»¶åä¸€è‡´
    expected_id = normalize_module_id(filename)
    manifest_id = manifest['id']

    if manifest_id != expected_id:
        return False, f"manifest.id ä¸åŒ¹é…: æ–‡ä»¶å='{expected_id}', manifest.id='{manifest_id}'"

    return True, None


def scan_modules_directory(directory_path):
    """
    æ‰«æç›®å½•ä¸­çš„æ‰€æœ‰æ¨¡å—ZIPæ–‡ä»¶
    è¿”å›: (valid_items, errors, skipped_files)
    """
    items = []
    errors = []
    skipped_files = []

    dir_path = Path(directory_path)

    if not dir_path.exists():
        print(f"âš ï¸  æ¨¡å—ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        return items, errors, skipped_files

    # éå†ç›®å½•ä¸­çš„æ‰€æœ‰ZIPæ–‡ä»¶
    for filepath in dir_path.glob('*.zip'):
        # è·³è¿‡index.json
        if filepath.name == 'index.json':
            continue

        try:
            # æ‰“å¼€ZIPæ–‡ä»¶
            with zipfile.ZipFile(filepath, 'r') as zip_file:
                # æŸ¥æ‰¾manifest.jsonï¼ˆå¯èƒ½åœ¨æ ¹ç›®å½•æˆ–å­ç›®å½•ä¸­ï¼‰
                manifest_file = None
                manifest_path = None

                for file_in_zip in zip_file.namelist():
                    if file_in_zip.endswith('manifest.json'):
                        manifest_file = file_in_zip
                        manifest_path = file_in_zip
                        break

                if manifest_file is None:
                    errors.append(f"âŒ {filepath.name}: ZIPä¸­æœªæ‰¾åˆ°manifest.json")
                    skipped_files.append(filepath.name)
                    continue

                # è¯»å–å¹¶è§£æmanifest.json
                with zip_file.open(manifest_file) as manifest_json:
                    manifest = json.load(manifest_json)

                # éªŒè¯manifest
                is_valid, error_msg = validate_module(manifest, filepath.name)

                if not is_valid:
                    errors.append(f"âŒ {filepath.name}: {error_msg}")
                    skipped_files.append(filepath.name)
                    continue

                # æ„å»ºç´¢å¼•æ¡ç›®
                item = {
                    'id': manifest.get('id', normalize_module_id(filepath.name)),
                    'name': manifest.get('name', 'æœªå‘½å'),
                    'description': manifest.get('description', ''),
                    'author': manifest.get('author', 'æœªçŸ¥'),
                    'version': manifest.get('version', '1.0.0'),
                    'category': manifest.get('category', 'ç”¨æˆ·è„šæœ¬'),
                    'homepage': manifest.get('homepage', ''),
                    'permissions': manifest.get('permissions', []),
                    'inputs': manifest.get('inputs', []),
                    'outputs': manifest.get('outputs', []),
                    'filename': filepath.name,
                    # æ„å»ºä¸‹è½½URL
                    'download_url': f"https://raw.githubusercontent.com/ChaoMixian/vFlow-Repos/main/modules/{filepath.name}",
                    # æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè„šæœ¬æ›´æ–°æ–‡ä»¶ï¼‰
                    'local_path': str(filepath)
                }

                items.append(item)

                print(f"âœ… {filepath.name}: {item['name']} (v{item['version']}, {item['category']})")

        except zipfile.BadZipFile:
            errors.append(f"âŒ {filepath.name}: æ— æ•ˆçš„ZIPæ–‡ä»¶")
            skipped_files.append(filepath.name)
        except json.JSONDecodeError as e:
            errors.append(f"âŒ {filepath.name}: manifest.jsonè§£æé”™è¯¯ - {str(e)}")
            skipped_files.append(filepath.name)
        except Exception as e:
            errors.append(f"âŒ {filepath.name}: {str(e)}")
            skipped_files.append(filepath.name)

    return items, errors, skipped_files


# ==================== ä¸»å‡½æ•° ====================

def generate_index(directory, item_type, scan_func, output_file='index.json'):
    """ç”Ÿæˆç´¢å¼•æ–‡ä»¶çš„é€šç”¨å‡½æ•°"""
    print(f"ğŸ” æ‰«æ{item_type}ç›®å½•: {directory}")
    print("=" * 60)

    # æ‰«ææ–‡ä»¶
    items, errors, skipped_files = scan_func(directory)

    # æ‰“å°é”™è¯¯å’Œè·³è¿‡çš„æ–‡ä»¶
    if errors:
        print("\nâŒ éªŒè¯å¤±è´¥:")
        for error in errors:
            print(f"  {error}")

    if skipped_files:
        print(f"\nâš ï¸  è·³è¿‡ {len(skipped_files)} ä¸ªæ–‡ä»¶")

    # æŒ‰IDæ’åº
    items.sort(key=lambda x: x['id'])

    # æ„å»ºç´¢å¼•
    index = {
        'version': '1.0',
        'last_updated': datetime.now().isoformat(),
        'total_count': len(items),
        f'{item_type}': items
    }

    # å†™å…¥ç´¢å¼•æ–‡ä»¶
    output_path = Path(directory) / output_file
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 60)
    print(f"âœ… æˆåŠŸç´¢å¼• {len(items)} ä¸ª{item_type}")
    print(f"ğŸ“ ç´¢å¼•æ–‡ä»¶: {output_path}")
    print(f"ğŸ• æ›´æ–°æ—¶é—´: {index['last_updated']}")

    return len(errors) == 0


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ vFlow ä»“åº“ç´¢å¼•ç”Ÿæˆå™¨")
    print("=" * 60)

    success = True

    # ç”Ÿæˆå·¥ä½œæµç´¢å¼•
    workflows_dir = 'workflows'
    if len(sys.argv) > 1:
        workflows_dir = sys.argv[1]

    if not generate_index(workflows_dir, 'workflows', scan_workflows_directory):
        success = False

    print("\n")

    # ç”Ÿæˆæ¨¡å—ç´¢å¼•
    modules_dir = 'modules'
    if len(sys.argv) > 2:
        modules_dir = sys.argv[2]

    if not generate_index(modules_dir, 'modules', scan_modules_directory):
        success = False

    # è¿”å›é€€å‡ºç 
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()